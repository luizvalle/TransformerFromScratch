{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNr4DhAtiWGawuBgz1WrKhp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luizvalle/TransformerFromScratch/blob/main/TransformersFromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "8lzMtAtFHNaf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(X, Y, W_Q, W_K, W_V):\n",
        "    num_input_tokens, dim_x = X.shape\n",
        "    num_context_tokens, dim_y = Y.shape\n",
        "    w_q_in_dim, w_q_out_dim = W_Q.shape\n",
        "    w_k_in_dim, w_k_out_dim = W_K.shape\n",
        "    w_v_in_dim, w_v_out_dim = W_V.shape\n",
        "\n",
        "    assert dim_x == w_q_in_dim\n",
        "    assert dim_y == w_k_in_dim\n",
        "    assert dim_y == w_v_in_dim\n",
        "    assert w_q_out_dim == w_k_out_dim\n",
        "    assert w_v_out_dim == w_q_out_dim\n",
        "\n",
        "    Q = X @ W_Q\n",
        "    K = Y @ W_K\n",
        "    V = Y @ W_V\n",
        "\n",
        "    A = np.exp(Q @ K.T / np.sqrt(w_q_out_dim))\n",
        "\n",
        "    assert A.shape[0] == num_input_tokens\n",
        "    assert A.shape[1] == num_context_tokens\n",
        "\n",
        "    S = A.sum(axis=1) # Sum each row\n",
        "    A_bar = A / S[:,np.newaxis] # Normalized A\n",
        "\n",
        "    assert all(A_bar.sum(axis=1).round(3) == 1) # Ensure all rows add up to 1\n",
        "\n",
        "    X_prime = A @ V\n",
        "\n",
        "    assert X_prime.shape[0] == num_input_tokens\n",
        "    assert X_prime.shape[1] == w_v_out_dim\n",
        "\n",
        "    return X_prime"
      ],
      "metadata": {
        "id": "oFo-jCb2HVp6"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 1], [1, 2]])\n",
        "Y = np.array([[1, 4], [1, -2]])\n",
        "W_Q = np.array([[1, 1, 2], [-1, -1, 2]])\n",
        "W_K = np.array([[0, 1, 0], [9, -4, 2]])\n",
        "W_V = np.array([[0, 1, 2], [-8, -1, 2]])\n",
        "attention(X, Y, W_Q, W_K, W_V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ0JWB9tJboD",
        "outputId": "f45e0ada-9a60-4c4f-dc10-08b1006d1927"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.67167691e+01,  5.17666536e+00, -3.00505381e+00],\n",
              "       [-1.88421715e+08, -1.76645357e+07,  5.88817858e+07]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    }
  ]
}
